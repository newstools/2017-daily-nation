I commend Education Cabinet Secretary Fred Matiang’i, and the chairman of the Kenya National Examinations Council (Knec), Prof George Magoha, for working hard to eradicate cheating in national exams. However, as the two continue to receive glowing tribute, we should not ignore the fact that they did not get it right in the KCSE exam results, which makes the grades the candidates scored questionable. To begin with, Knec ignored key roles played by subject awards panels in grading candidates. It also ignored rules and procedures that guide grading of candidates in external examinations. There is evidence that the exams council used raw scores to grade the candidates, which is not only a deviation from the past, but a serious breach of international standards of assessments. One of the most important stages in the administration of exams is the awarding of grades. A universal principle in grading is that candidates’ performance must be compared with something else. There are two types of grading: norm-referenced and criterion-referenced. In norm-referenced grading, candidates are awarded their grades based on their relative standing among other candidates. In criterion-referenced grading, candidates’ grades are determined by mastering expected learning outcomes. Since Knec shifted to criterion-referenced grading, it has been possible for many students to achieve top grades based on agreed criteria. EXPERTS’ PANELS The criteria for grading is agreed upon by panels of experts that include curriculum specialists and test developers. Therefore, the large number of A grades in some schools in the past years may have been deserved. Therefore, what missed in the 2016 KCSE exam results was moderation by education specialists, according to established principles of assessment. A raw score by itself has no meaning. If, for example, a candidate obtains a score of 70 per cent in chemistry and 55 per cent in mathematics, one cannot conclude that the candidate performed better in chemistry without first comparing their performance with other scores in each set. Similarly, the merit of a mark of 45 per cent in a very difficult exam is not the same as the merit of a mark of 45 per cent in an easy test. The standard practice is that the comparison of candidates’ performances in different exam papers is done by first transforming the raw scores into standard scores – such as Z score, T score, Scholastic Aptitude Test scores, Stanines and Grade Point Average. Eminent educational assessment experts such as Norman Gronlund and Thorndike have emphasised this point as follows: that a raw score has no direct meaning or significance. SOME STANDARD The score only has meaning when we have some standard to which to compare it. This means that raw scores have to be interpreted by a panel of experts – including curriculum specialists, test developers and quality assurance and standards officers – before they can be used for assigning grades. Therefore, the lack of many A grades in the exam as in the past or the increase in E grades cannot be explained merely by the claim that there was no cheating in the exams. The CS and the Knec chairman should avoid making statements that produce a feeling of shame and embarrassment in teachers and students. For instance, a statement attributed to Prof Magoha, that 50 per cent of students undertaking various courses in universities are fake, is regrettable. Since the universal principles of assessment were not used to assign grades, Dr Matiang’i should eat humble pie and revoke the 2016 KCSE exam results and allow subject awards panels to do their job.  Prof Paul Namwonza teaches educational assessment and evaluation at Catholic University of Eastern Africa and is chairman, Society of Educational Research and Evaluation in Kenya. ogulapaul@gmail.com  